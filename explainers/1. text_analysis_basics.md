# Understanding Text Analysis: From Words to Meaning
## A Guide to Descriptive Text Statistics

by Steven Denney

---

## Introduction: Why Count Words?

When we analyze text computationally, we start with the most basic question: **What words appear, and how often?**

But not all words are equally important. Some appear everywhere. Some appear rarely but meaningfully. Some distinguish one type of document from another.

This guide explains the key metrics we use to move from **raw word counts** to **meaningful patterns**.

---

## 1. Word Frequency (Term Frequency / TF)

### What It Is:
**The simplest measure: How many times does a word appear?**

### Example:
In a Korean history textbook:
- ì—­ì‚¬ (history) appears 150 times
- ê¸°ì›ì „ (BCE) appears 54 times
- ë¬¸í™” (culture) appears 32 times

### What It Tells Us:
- Which topics are discussed most
- The basic vocabulary of the corpus
- Surface-level content overview

### Limitations:
**High frequency â‰  high importance**

Common words like "í•˜ë‹¤" (to do), "ê²ƒ" (thing), "ìˆë‹¤" (to exist) appear frequently but carry little meaning. This is why we remove **stopwords**.

### In Orange:
- **Word Cloud** - visual display of frequency (bigger = more frequent)
- **Data Table** after Bag of Words - raw counts

---

## 2. Bag of Words (BoW)

### What It Is:
**A way of representing text as numbers that computers can analyze.**

Each document becomes a vector (row) where each word is a feature (column) with a count.

### Example:

| Document | ì—­ì‚¬ | ê¸°ì›ì „ | ë¬¸í™” | ë…ë¦½ |
|----------|------|--------|------|------|
| Doc 1    | 5    | 8      | 2    | 0    |
| Doc 2    | 3    | 0      | 4    | 7    |
| Doc 3    | 6    | 1      | 3    | 2    |

Document 1 contains "ì—­ì‚¬" 5 times, "ê¸°ì›ì „" 8 times, etc.

### What It Tells Us:
- Transforms text into analyzable data
- Enables comparison between documents
- Foundation for most text analysis methods

### Key Assumption:
**"The meaning of a document can be captured by which words it contains, ignoring word order"**

This is called the **"bag" metaphor** - like dumping all words into a bag and counting them.

### Limitations:
- **Loses context**: "not good" vs "good" - both have "good" but opposite meanings
- **Loses grammar**: word order doesn't matter
- **High dimensionality**: thousands of columns (one per unique word)

### In Orange:
- **Bag of Words widget** - creates this representation
- Input: preprocessed text
- Output: document-term matrix

---

## 3. Document Frequency (DF)

### What It Is:
**How many documents contain a word? (Not how many times total)**

### Example:
- ì—­ì‚¬ appears in 45 out of 50 documents (DF = 45)
- ê¸°ì›ì „ appears in 12 out of 50 documents (DF = 12)
- ë…ë¦½ìš´ë™ appears in 3 out of 50 documents (DF = 3)

### What It Tells Us:
- How widespread vs. specialized a word is
- Common vocabulary vs. rare/technical terms

### Two Extremes:
**High DF (appears in most documents):**
- Very common words
- General vocabulary
- Less distinctive

**Low DF (appears in few documents):**
- Specialized terms
- Topic-specific vocabulary
- More distinctive

---

## 4. Inverse Document Frequency (IDF)

### What It Is:
**A weight that increases a word's importance if it's rare across documents.**

**Formula (simplified):**
```
IDF = log(Total Documents / Documents Containing Word)
```

### Intuition:
- Words in ALL documents â†’ low IDF (not distinctive)
- Words in FEW documents â†’ high IDF (distinctive!)

### Example:
**Corpus of 50 Korean history textbooks:**

| Word | Document Frequency | IDF Score |
|------|-------------------|-----------|
| ì—­ì‚¬ | 48/50 documents | 0.04 (LOW) |
| ê¸°ì›ì „ | 35/50 documents | 0.15 |
| ì‚¼êµ­ì‹œëŒ€ | 15/50 documents | 0.52 |
| ê°‘ì˜¤ê°œí˜ | 5/50 documents | 1.00 (HIGH) |

**Interpretation:**
- ì—­ì‚¬ appears in almost every textbook â†’ not distinctive â†’ low IDF
- ê°‘ì˜¤ê°œí˜ appears in only a few â†’ distinctive â†’ high IDF

### Why This Matters:
**IDF helps us find distinctive words, not just frequent ones.**

---

## 5. TF-IDF (Term Frequency - Inverse Document Frequency)

### What It Is:
**The most important metric: Combines frequency WITH distinctiveness**

**Formula:**
```
TF-IDF = (How often in this document) Ã— (How rare across all documents)
```

### How It Works:

**High TF-IDF means:**
- Word appears OFTEN in this document (high TF)
- Word is RARE across the corpus (high IDF)
- = **Distinctive and important for THIS document**

**Low TF-IDF means:**
- Either: appears rarely in this document
- Or: appears in most documents (not distinctive)
- = Not particularly important

### Example:

**Document about ê°‘ì˜¤ê°œí˜ (Gabo Reform):**

| Word | Frequency in Doc | IDF | TF-IDF |
|------|-----------------|-----|--------|
| ì—­ì‚¬ | 8 times | 0.04 | 0.32 (LOW) |
| ê°œí˜ | 12 times | 0.45 | 5.40 |
| ê°‘ì˜¤ê°œí˜ | 15 times | 1.00 | 15.00 (HIGH!) |

**Interpretation:**
- ì—­ì‚¬ appears often but isn't distinctive for THIS document
- ê°‘ì˜¤ê°œí˜ appears often AND is rare overall = highly distinctive for this document

### What TF-IDF Tells Us:
**"What words are most CHARACTERISTIC of each document?"**

Not just "what appears most" but **"what makes this document unique"**

### In Orange:
- **Extract Keywords widget** - uses TF-IDF
- **Bag of Words widget** - has TF-IDF option
- Shows which words best represent each document

---

## Putting It All Together: A Comparison

**Scenario:** Analyzing 3 Korean history textbook chapters

### Chapter 1: Ancient Korea (ì‚¼êµ­ì‹œëŒ€)
- **Most Frequent:** ì—­ì‚¬, ì‹œëŒ€, êµ­ê°€, ì™•
- **Highest TF-IDF:** ì‚¼êµ­ì‹œëŒ€, ê³ êµ¬ë ¤, ë°±ì œ, ì‹ ë¼

### Chapter 2: Japanese Occupation (ì¼ì œê°•ì ê¸°)
- **Most Frequent:** ì—­ì‚¬, ì‹œëŒ€, êµ­ê°€, ì¼ë³¸
- **Highest TF-IDF:** ë…ë¦½ìš´ë™, ì¼ì œ, ì €í•­, ë§Œì„¸

### Chapter 3: Modern Korea (í˜„ëŒ€)
- **Most Frequent:** ì—­ì‚¬, ì‹œëŒ€, êµ­ê°€, ë°œì „
- **Highest TF-IDF:** ë¯¼ì£¼í™”, ê²½ì œ, ì‚°ì—…í™”, ê°œë°œ

**Notice:**
- **Frequency alone** - "ì—­ì‚¬" tops all chapters (not helpful for distinguishing!)
- **TF-IDF** - shows what makes EACH chapter unique

---

## Common Student Questions

### Q: "Why remove stopwords? They're frequent for a reason!"

**A:** Stopwords (like í•˜ë‹¤, ìˆë‹¤, ê²ƒ) appear frequently but don't help us understand CONTENT. They're grammatical scaffolding, not meaning.

Think of it like this: If analyzing English news, "the" appears everywhere. Doesn't tell us if an article is about sports vs. politics.

### Q: "Why is TF-IDF better than just counting?"

**A:** Raw counts reward common words. TF-IDF rewards **distinctive** words.

Example: ì—­ì‚¬ (history) appears 100 times across 50 history textbooks. Not surprising, not distinctive. ê°‘ì˜¤ê°œí˜ appears 50 times but only in 3 textbooks about that specific reform. VERY distinctive!

### Q: "Can't important words be common?"

**A:** Yes! That's why we look at BOTH metrics:
- Word clouds show **what's discussed most** (frequency)
- TF-IDF shows **what's distinctive** (characteristic vocabulary)

Use both to tell a complete story.

### Q: "Why does preprocessing matter?"

**A:** Preprocessing determines WHAT gets counted:
- Keep all words â†’ noise dominates
- Remove stopwords â†’ content words emerge
- Keep only nouns â†’ different story than nouns+verbs

**Preprocessing = analytical choices that affect results!**

---

## From Descriptive to Interpretive: Making Claims

### Descriptive Claims (What you see):
- âœ… "ê¸°ì›ì „ appears 54 times"
- âœ… "ë¯¼ì¡± has the highest TF-IDF score"
- âœ… "This cluster contains 15 documents"

### Interpretive Claims (What it might mean):
- ğŸ¤” "The high frequency of ê¸°ì›ì „ suggests emphasis on ancient history"
- ğŸ¤” "The prominence of ë¯¼ì¡± indicates nationalist discourse"
- ğŸ¤” "Documents cluster by historical period"

### Critical Claims (Limitations):
- âš ï¸ "However, frequency doesn't capture how these terms are used in context"
- âš ï¸ "TF-IDF may overweight rare technical terms"
- âš ï¸ "These patterns could also be explained by..."

---

## Visual Summary: Which Metric When?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RESEARCH QUESTION          â†’    USE THIS METRIC    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  What's discussed most?     â†’    Word Frequency     â”‚
â”‚  What topics appear?        â†’    Word Cloud         â”‚
â”‚  What makes docs similar?   â†’    Bag of Words       â”‚
â”‚  What's distinctive?        â†’    TF-IDF             â”‚
â”‚  What defines clusters?     â†’    TF-IDF by cluster  â”‚
â”‚  How do groups differ?      â†’    Keyword contrast   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Workflow in Orange: The Pipeline

```
1. Raw Text
   â†“
2. Preprocessing 
   - Korean morphological analysis
   - POS tagging
   - Stopword removal
   â†“
3. Bag of Words
   - Convert to numbers
   - Count words per document
   â†“
4. Analysis Options:
   â†’ Word Cloud (frequency)
   â†’ Extract Keywords (TF-IDF)
   â†’ Hierarchical Clustering (find patterns)
   â†’ Compare groups (keyword contrast)
```

---

## Practice Exercise

**Given this information about 3 documents:**

| Document | ì—­ì‚¬ (TF) | ì—­ì‚¬ (IDF) | ë…ë¦½ (TF) | ë…ë¦½ (IDF) |
|----------|-----------|------------|-----------|------------|
| Doc A    | 10        | 0.1        | 0         | 0.8        |
| Doc B    | 8         | 0.1        | 15        | 0.8        |
| Doc C    | 12        | 0.1        | 2         | 0.8        |

**Questions:**
1. Which document is most about ë…ë¦½ (independence)?
2. Which word is more distinctive: ì—­ì‚¬ or ë…ë¦½?
3. What would be the TF-IDF for ë…ë¦½ in Doc B

**Answers:**
1. Doc B (TF = 15, highest frequency)
2. ë…ë¦½ (IDF = 0.8 vs. 0.1) - appears in fewer documents
3. TF-IDF = 15 Ã— 0.8 = 12.0 (high)

---

## Key Takeaways

**Remember:**

1. **Frequency** = What appears most
2. **Document Frequency** = How widespread a word is
3. **IDF** = How distinctive/rare a word is
4. **TF-IDF** = Frequency Ã— Distinctiveness = What's characteristic

**For your analysis:**
- Use **word frequency** to understand general content
- Use **TF-IDF** to find distinctive vocabulary
- Use **both** to tell a complete story
- Always **justify interpretations** with descriptive evidence

**The goal:** Move from "here's what the data shows" to "here's what it might mean" - while staying honest about limitations!

---

## Questions for Reflection

As you work with these metrics in your own analysis:

1. **What does high frequency tell you? What doesn't it tell you?**
2. **When might TF-IDF be misleading?**
3. **How do your preprocessing choices affect these metrics?**
4. **What's the difference between describing patterns and interpreting them?**

Remember: **Computational text analysis is a tool, not an answer.** Your job is to use these metrics thoughtfully to make evidence-based interpretations while acknowledging their limitations and supporting them with (your) domain expertise. This is a good combination of data skills and area studies expertise. 
